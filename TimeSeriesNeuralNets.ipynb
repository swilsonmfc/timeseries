{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage.filters import convolve1d\n",
    "\n",
    "from pprint import pprint\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinations\n",
    "* There are several combinations of approaches to handling time series\n",
    "* Time Series\n",
    "    * Univariate \n",
    "    * Multivariate\n",
    "* Model Choice\n",
    "    * ETS\n",
    "    * SARIMAX\n",
    "    * Prophet\n",
    "    * Machine Learning\n",
    "    * RNN (LSTM, GRU)\n",
    "    * CNN\n",
    "* Output \n",
    "    * One Step\n",
    "    * Multi Step\n",
    "    * Parallel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "* Brief, high Level overview of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/2739/1*L9xLcwKhuZ2cuS8fF0ZjwA.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://miro.medium.com/max/2739/1*L9xLcwKhuZ2cuS8fF0ZjwA.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.researchgate.net/profile/Muhammad_Hamdan9/publication/327435257/figure/fig4/AS:742898131812354@1554132125449/Activation-Functions-ReLU-Tanh-Sigmoid.ppm\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://www.researchgate.net/profile/Muhammad_Hamdan9/publication/327435257/figure/fig4/AS:742898131812354@1554132125449/Activation-Functions-ReLU-Tanh-Sigmoid.ppm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/2622/1*eJ36Jpf-DE9q5nKk67xT0Q.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://miro.medium.com/max/2622/1*eJ36Jpf-DE9q5nKk67xT0Q.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/2313/1*DcLWqOojI1b9jzQaLibUkQ.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://miro.medium.com/max/2313/1*DcLWqOojI1b9jzQaLibUkQ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate - One Step Ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "* Univariate, One Step Prediction\n",
    "* What number is next in the sequence?\n",
    "* We want to turn this into a supervised learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate to Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subseries(series, steps=3):\n",
    "    X, y = [], []\n",
    "    size = len(series)\n",
    "    for index in range(size):\n",
    "        if index + steps > size - 1:\n",
    "            break\n",
    "        seqX = series[index:index + steps]\n",
    "        seqY = series[index + steps]\n",
    "        X.append(seqX)\n",
    "        y.append(seqY)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] 40\n",
      "[20 30 40] 50\n",
      "[30 40 50] 60\n",
      "[40 50 60] 70\n",
      "[50 60 70] 80\n",
      "[60 70 80] 90\n",
      "[70 80 90] 100\n"
     ]
    }
   ],
   "source": [
    "steps = 3\n",
    "X, y = subseries(series)\n",
    "for index in range(len(X)):\n",
    "    print(X[index], y[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "* This next code block is dense in terms of learning\n",
    "    * Sequential\n",
    "    * Dense\n",
    "    * Activation - Relu\n",
    "    * Input Dimension\n",
    "    * Compile\n",
    "    * Optimizer - Adam\n",
    "    * Loss - mse\n",
    "    * Fit - Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=steps))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X, y, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 501\n",
      "Trainable params: 501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[110.84832]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = np.array([80, 90, 100]) # --> 110\n",
    "X_pred = X_pred.reshape((1, X.shape[1]))\n",
    "model.predict(X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate - Multiple Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "* Similar to the univariate model\n",
    "* We have a single time series\n",
    "* We want a model that can output n steps into the future\n",
    "* Which is a generalization of the single step problem where steps = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate to MultiStep\n",
    "* We want to grab the 1st, 2nd, and 3rd items in the series\n",
    "* Predict the 4th & 5th item\n",
    "* Continue to the end of the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subseriesMultistep(series, steps=3, output=2):\n",
    "    X, y = [], []\n",
    "    size = len(series)\n",
    "    for index in range(size):\n",
    "        if index + steps > size - output:\n",
    "            break\n",
    "        seqX = series[index:index + steps]\n",
    "        seqY = series[index + steps: index + steps + output]\n",
    "        X.append(seqX)\n",
    "        y.append(seqY)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] [40 50]\n",
      "[20 30 40] [50 60]\n",
      "[30 40 50] [60 70]\n",
      "[40 50 60] [70 80]\n",
      "[50 60 70] [80 90]\n",
      "[60 70 80] [ 90 100]\n"
     ]
    }
   ],
   "source": [
    "steps  = 3\n",
    "output = 2\n",
    "X, y = subseriesMultistep(series, steps, output)\n",
    "for index in range(len(X)):\n",
    "    print(X[index], y[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=steps))\n",
    "model.add(Dense(output))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X, y, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[110.62564, 121.8443 ]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = np.array([80, 90, 100]) # --> [110, 120]\n",
    "X_pred = X_pred.reshape((1, X.shape[1]))\n",
    "model.predict(X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate - One Step Ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "* We have two series of numbers\n",
    "* We would like to have them added together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 60,  90, 120, 150, 180, 210, 240, 270, 300, 330])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series1 = np.array([10, 20, 30, 40,  50,  60,  70,  80,  90,  100])\n",
    "series2 = np.array([50, 70, 90, 110, 130, 150, 170, 190, 210, 230])\n",
    "seriesY = np.add(series1, series2)\n",
    "seriesY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape\n",
    "* Our data is in series\n",
    "* We need our data in X, Y, Z format (X + Y = Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  50,  60],\n",
       "       [ 20,  70,  90],\n",
       "       [ 30,  90, 120],\n",
       "       [ 40, 110, 150],\n",
       "       [ 50, 130, 180],\n",
       "       [ 60, 150, 210],\n",
       "       [ 70, 170, 240],\n",
       "       [ 80, 190, 270],\n",
       "       [ 90, 210, 300],\n",
       "       [100, 230, 330]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series1 = series1.reshape((series1.shape[0], 1))\n",
    "series2 = series2.reshape((series2.shape[0], 1))\n",
    "seriesY = seriesY.reshape((seriesY.shape[0], 1))\n",
    "data = np.hstack((series1, series2, seriesY))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate to Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subseriesMultivariate(series, steps=3):\n",
    "    X, y = [], []\n",
    "    size = len(series)\n",
    "    for index in range(size):\n",
    "        if index + steps > size - 1:\n",
    "            break\n",
    "        seqX = series[index :index + steps, :-1]\n",
    "        seqY = series[index + steps - 1, -1]\n",
    "        X.append(seqX)\n",
    "        y.append(seqY)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 50]\n",
      " [20 70]\n",
      " [30 90]] 120\n",
      "[[ 20  70]\n",
      " [ 30  90]\n",
      " [ 40 110]] 150\n",
      "[[ 30  90]\n",
      " [ 40 110]\n",
      " [ 50 130]] 180\n",
      "[[ 40 110]\n",
      " [ 50 130]\n",
      " [ 60 150]] 210\n",
      "[[ 50 130]\n",
      " [ 60 150]\n",
      " [ 70 170]] 240\n",
      "[[ 60 150]\n",
      " [ 70 170]\n",
      " [ 80 190]] 270\n",
      "[[ 70 170]\n",
      " [ 80 190]\n",
      " [ 90 210]] 300\n"
     ]
    }
   ],
   "source": [
    "X_mv, y_mv = subseriesMultivariate(data, steps=3)\n",
    "for index in range(len(X_mv)):\n",
    "    print(X_mv[index], y_mv[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3, 2)\n",
      "(7, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 10,  50,  20,  70,  30,  90],\n",
       "       [ 20,  70,  30,  90,  40, 110],\n",
       "       [ 30,  90,  40, 110,  50, 130],\n",
       "       [ 40, 110,  50, 130,  60, 150],\n",
       "       [ 50, 130,  60, 150,  70, 170],\n",
       "       [ 60, 150,  70, 170,  80, 190],\n",
       "       [ 70, 170,  80, 190,  90, 210]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_mv.shape)\n",
    "n_input = X_mv.shape[1] * X_mv.shape[2]\n",
    "data = X_mv.reshape((X.shape[0], n_input))\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=n_input))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(data, y_mv, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[332.39563]]\n"
     ]
    }
   ],
   "source": [
    "X_pred = np.array([[80, 190], [90, 210], [100, 230]])\n",
    "X_pred = X_pred.reshape((1, n_input))\n",
    "y_hat = model.predict(X_pred, verbose=0)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate - Multiple Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 60,  90, 120, 150, 180, 210, 240, 270, 300, 330])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series1 = np.array([10, 20, 30, 40,  50,  60,  70,  80,  90,  100])\n",
    "series2 = np.array([50, 70, 90, 110, 130, 150, 170, 190, 210, 230])\n",
    "seriesY = np.add(series1, series2)\n",
    "seriesY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  50,  60],\n",
       "       [ 20,  70,  90],\n",
       "       [ 30,  90, 120],\n",
       "       [ 40, 110, 150],\n",
       "       [ 50, 130, 180],\n",
       "       [ 60, 150, 210],\n",
       "       [ 70, 170, 240],\n",
       "       [ 80, 190, 270],\n",
       "       [ 90, 210, 300],\n",
       "       [100, 230, 330]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series1 = series1.reshape((series1.shape[0], 1))\n",
    "series2 = series2.reshape((series2.shape[0], 1))\n",
    "seriesY = seriesY.reshape((seriesY.shape[0], 1))\n",
    "data = np.hstack((series1, series2, seriesY))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate to MultiStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subseriesMultivariate(series, steps=3, output=2):\n",
    "    X, y = [], []\n",
    "    size = len(series)\n",
    "    for index in range(size):\n",
    "        if index + steps > size - output:\n",
    "            break\n",
    "        seqX = series[index :index + steps, :-1]\n",
    "        seqY = series[index + steps - 1 :index + steps + output -1, -1]\n",
    "        X.append(seqX)\n",
    "        y.append(seqY)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 50]\n",
      " [20 70]\n",
      " [30 90]] [120 150]\n",
      "[[ 20  70]\n",
      " [ 30  90]\n",
      " [ 40 110]] [150 180]\n",
      "[[ 30  90]\n",
      " [ 40 110]\n",
      " [ 50 130]] [180 210]\n",
      "[[ 40 110]\n",
      " [ 50 130]\n",
      " [ 60 150]] [210 240]\n",
      "[[ 50 130]\n",
      " [ 60 150]\n",
      " [ 70 170]] [240 270]\n",
      "[[ 60 150]\n",
      " [ 70 170]\n",
      " [ 80 190]] [270 300]\n"
     ]
    }
   ],
   "source": [
    "steps  = 3\n",
    "output = 2\n",
    "X_mv, y_mv = subseriesMultivariate(data, steps=steps, output=output)\n",
    "for index in range(len(X_mv)):\n",
    "    print(X_mv[index], y_mv[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 2)\n",
      "(6, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 10,  50,  20,  70,  30,  90],\n",
       "       [ 20,  70,  30,  90,  40, 110],\n",
       "       [ 30,  90,  40, 110,  50, 130],\n",
       "       [ 40, 110,  50, 130,  60, 150],\n",
       "       [ 50, 130,  60, 150,  70, 170],\n",
       "       [ 60, 150,  70, 170,  80, 190]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_mv.shape)\n",
    "n_input = X_mv.shape[1] * X_mv.shape[2]\n",
    "data = X_mv.reshape((X.shape[0], n_input))\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=n_input))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(data, y_mv, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333.90652 366.3522 ]]\n"
     ]
    }
   ],
   "source": [
    "X_pred = np.array([[80, 190], [90, 210], [100, 230]])\n",
    "X_pred = X_pred.reshape((1, n_input))\n",
    "y_hat = model.predict(X_pred, verbose=0)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/750/1*T_ECcHZWpjn0Ki4_4BEzow.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://miro.medium.com/max/750/1*T_ECcHZWpjn0Ki4_4BEzow.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.researchgate.net/profile/Lei_Tai/publication/311805526/figure/fig3/AS:667790805565446@1536225143793/Recurrent-Neural-Network-Structure-The-left-is-the-typical-RNN-structure-The-right-part.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://www.researchgate.net/profile/Lei_Tai/publication/311805526/figure/fig3/AS:667790805565446@1536225143793/Recurrent-Neural-Network-Structure-The-left-is-the-typical-RNN-structure-The-right-part.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN\n",
    "* RNNs\n",
    "    * Train relatively quickly\n",
    "    * Suffer from short term memory\n",
    "* Challenges\n",
    "    * http://proceedings.mlr.press/v28/pascanu13.pdf\n",
    "    * Vanishing gradients --> Zero\n",
    "    * Exploding gradients --> Infinity (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://decker.com/wp-content/uploads/2017/09/telephone-game-kids-whispering.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://decker.com/wp-content/uploads/2017/09/telephone-game-kids-whispering.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanishing 1.0000000000000002e-10\n",
      "Exploding 10000000000\n"
     ]
    }
   ],
   "source": [
    "small_error = 0.01\n",
    "large_error = 100\n",
    "\n",
    "print(f'Vanishing {small_error ** 5}')\n",
    "print(f'Exploding {large_error ** 5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "* https://www.researchgate.net/publication/13853244_Long_Short-term_Memory\n",
    "* Long short term memory\n",
    "* How do we avoid vanishing gradients!  \n",
    "    * Short term memory\n",
    "    * Long term memory\n",
    "* Key takeaways:\n",
    "    * Long term memory (Ct) can pass through\n",
    "    * LSTM is computationally expensive\n",
    "* Not the only approach\n",
    "    * LSTM Long Short Term Memory\n",
    "    * GRU Gated Recurrent Unit (Faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://chunml.github.io/images/projects/creating-text-generator-using-recurrent-neural-network/LSTM.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://chunml.github.io/images/projects/creating-text-generator-using-recurrent-neural-network/LSTM.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape\n",
    "* Our data is in [samples, input_features] shape\n",
    "* We need data in [samples, timesteps, output_features] shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "* Input [samples, features]\n",
    "* Input data has 7 samples\n",
    "* Input data has 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3) (7,)\n"
     ]
    }
   ],
   "source": [
    "steps = 3\n",
    "X, y = subseries(series, steps=steps)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "* Reshaped [samples, timesteps, features]\n",
    "* Reshaped data has 7 samples (rows in X)\n",
    "* Reshaped data has 3 timesteps (our input data's features)\n",
    "* Reshaped data has 1 feature (one value of the timestep at a time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3, 1) (7,)\n"
     ]
    }
   ],
   "source": [
    "features = 1\n",
    "X = X.reshape(X.shape[0], steps, features)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "* LSTM\n",
    "* Input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0304 20:32:44.914070 140735617508224 deprecation.py:323] From /Users/wilsons/anaconda3/envs/pyjup/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(steps, features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109.55472]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = np.array([80, 90, 100])\n",
    "X_pred = X_pred.reshape((1, steps, features))\n",
    "y_hat = model.predict(X_pred, verbose=0)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding\n",
    "* Imagine we're sliding a window across the sequence\n",
    "* We look at just the values in the window (size)\n",
    "* Then slide it to the right n positions (stride)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "size   = 3\n",
    "for index in range(len(series) - size + 1):\n",
    "    print(series[index : index + size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel / Filter\n",
    "* We take the values in the window and multiply by weights\n",
    "* In Conv1D layers, we specify how many filters / kernels / feature maps we want\n",
    "* When you hear filter / kernel / feature map think weights that we learn from data\n",
    "* We randomly initiatlize a filter, but for illustrative purposes I set them\n",
    "    * Identity\n",
    "    * Doubler\n",
    "* After we apply the kernel we sum the weighted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution1D(series, filter1D):\n",
    "    values = []\n",
    "    size = len(filter1D)\n",
    "    for index in range(len(series) - size + 1):\n",
    "        window   = series[index : index + size] \n",
    "        filtered = window * filter1D\n",
    "        summed   = filtered.sum()\n",
    "        print(f'Window {window}  * Filter {filter1D}  = {filtered}  --> Sum {summed}')\n",
    "        values.append(summed)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window [10, 20, 30]  * Filter [1 1 1]  = [10 20 30]  --> Sum 60\n",
      "Window [20, 30, 40]  * Filter [1 1 1]  = [20 30 40]  --> Sum 90\n",
      "Window [30, 40, 50]  * Filter [1 1 1]  = [30 40 50]  --> Sum 120\n",
      "Window [40, 50, 60]  * Filter [1 1 1]  = [40 50 60]  --> Sum 150\n",
      "Window [50, 60, 70]  * Filter [1 1 1]  = [50 60 70]  --> Sum 180\n",
      "Window [60, 70, 80]  * Filter [1 1 1]  = [60 70 80]  --> Sum 210\n",
      "Window [70, 80, 90]  * Filter [1 1 1]  = [70 80 90]  --> Sum 240\n",
      "Window [80, 90, 100]  * Filter [1 1 1]  = [ 80  90 100]  --> Sum 270\n",
      "Convolution: [60, 90, 120, 150, 180, 210, 240, 270]\n"
     ]
    }
   ],
   "source": [
    "# Identity\n",
    "c = convolution1D(series, np.array([1,1,1]))\n",
    "print(f'Convolution: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*tfESmBDSXnJzBMFxPvqZzg.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*tfESmBDSXnJzBMFxPvqZzg.gif\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window [10 20 30]  * Filter [2, 2, 2]  = [20 40 60]  --> Sum 120\n",
      "Window [20 30 40]  * Filter [2, 2, 2]  = [40 60 80]  --> Sum 180\n",
      "Window [30 40 50]  * Filter [2, 2, 2]  = [ 60  80 100]  --> Sum 240\n",
      "Window [40 50 60]  * Filter [2, 2, 2]  = [ 80 100 120]  --> Sum 300\n",
      "Window [50 60 70]  * Filter [2, 2, 2]  = [100 120 140]  --> Sum 360\n",
      "Window [60 70 80]  * Filter [2, 2, 2]  = [120 140 160]  --> Sum 420\n",
      "Window [70 80 90]  * Filter [2, 2, 2]  = [140 160 180]  --> Sum 480\n",
      "Window [ 80  90 100]  * Filter [2, 2, 2]  = [160 180 200]  --> Sum 540\n",
      "Convolution: [120, 180, 240, 300, 360, 420, 480, 540]\n"
     ]
    }
   ],
   "source": [
    "# Doubler\n",
    "c = convolution1D(series, np.array([2,2,2]))\n",
    "print(f'Convolution: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What about?\n",
    "[0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window [10, 20, 30]  * Filter [0 0 1]  = [ 0  0 30]  --> Sum 30\n",
      "Window [20, 30, 40]  * Filter [0 0 1]  = [ 0  0 40]  --> Sum 40\n",
      "Window [30, 40, 50]  * Filter [0 0 1]  = [ 0  0 50]  --> Sum 50\n",
      "Window [40, 50, 60]  * Filter [0 0 1]  = [ 0  0 60]  --> Sum 60\n",
      "Window [50, 60, 70]  * Filter [0 0 1]  = [ 0  0 70]  --> Sum 70\n",
      "Window [60, 70, 80]  * Filter [0 0 1]  = [ 0  0 80]  --> Sum 80\n",
      "Window [70, 80, 90]  * Filter [0 0 1]  = [ 0  0 90]  --> Sum 90\n",
      "Window [80, 90, 100]  * Filter [0 0 1]  = [  0   0 100]  --> Sum 100\n"
     ]
    }
   ],
   "source": [
    "c = convolution1D(series, np.array([0, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 60,  90, 120, 150, 180, 210, 240, 270])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [1, 1, 1]\n",
    "start = 1\n",
    "end   = len(weights) - start\n",
    "\n",
    "scipy.ndimage.filters.convolve1d(series, weights = weights, origin=start, mode='constant')[: -end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling 1D\n",
    "* Max pooling down samples the prior convolutions\n",
    "* Helps with location invariance\n",
    "* This is often applied in computer vision, but used in time series\n",
    "* To complete max pooling, we slide over the convolved values with a window (size)\n",
    "* We take the max value in that window.\n",
    "* Then we slide the window over to the right (stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool1D(series, size=2):\n",
    "    values = []\n",
    "    for index in range(len(series) - size + 1):\n",
    "        window = series[index : index + size]\n",
    "        maxed  = max(window)\n",
    "        values.append(maxed)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window [10 20 30]  * Filter [1, 1, 1]  = [10 20 30]  --> Sum 60\n",
      "Window [20 30 40]  * Filter [1, 1, 1]  = [20 30 40]  --> Sum 90\n",
      "Window [30 40 50]  * Filter [1, 1, 1]  = [30 40 50]  --> Sum 120\n",
      "Window [40 50 60]  * Filter [1, 1, 1]  = [40 50 60]  --> Sum 150\n",
      "Window [50 60 70]  * Filter [1, 1, 1]  = [50 60 70]  --> Sum 180\n",
      "Window [60 70 80]  * Filter [1, 1, 1]  = [60 70 80]  --> Sum 210\n",
      "Window [70 80 90]  * Filter [1, 1, 1]  = [70 80 90]  --> Sum 240\n",
      "Window [ 80  90 100]  * Filter [1, 1, 1]  = [ 80  90 100]  --> Sum 270\n",
      "Convolution: [60, 90, 120, 150, 180, 210, 240, 270]\n",
      "MaxPool:     [90, 120, 150, 180, 210, 240, 270]\n"
     ]
    }
   ],
   "source": [
    "# Identity\n",
    "c = convolution1D(series, [1,1,1])\n",
    "print(f'Convolution: {c}')\n",
    "\n",
    "m = maxpool1D(c)\n",
    "print(f'MaxPool:     {m}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap Convolution\n",
    "* Convolution\n",
    "    * Filter slides over data\n",
    "        * You decide on stride\n",
    "        * You decide on padding\n",
    "        * Back propagation will update your filter's weight\n",
    "    * Element-wise multiplication and addition\n",
    "    * Useful for position / location invariance\n",
    "    * Weight resharing (fewer parameters)\n",
    "* Max Pooling\n",
    "    * Down samples data\n",
    "    * Helpful for position invariance\n",
    "    * Other approaches (average pooling)\n",
    "    * Common in deep learning for computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1D\n",
    "* Use a Conv1D layer in a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3) (7,)\n"
     ]
    }
   ],
   "source": [
    "steps = 3\n",
    "X, y = subseries(series, steps=steps)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3, 1) (7,)\n"
     ]
    }
   ],
   "source": [
    "features = 1\n",
    "X = X.reshape(X.shape[0], steps, features)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0304 20:54:33.206201 140735617508224 deprecation_wrapper.py:119] From /Users/wilsons/anaconda3/envs/pyjup/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 2, activation='relu', input_shape=(steps, features)))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X, y, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 2, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,493\n",
      "Trainable params: 3,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111.74727]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = np.array([80, 90, 100])\n",
    "X_pred = X_pred.reshape((1, steps, features))\n",
    "y_hat = model.predict(X_pred)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "* Many ways to use neural networks for sequences (time series)\n",
    "    * Focus on buiding sequences (numpy)\n",
    "    * Nets give you flexibility in composition\n",
    "* Feed Forward Network\n",
    "* Recurrent (LSTM)\n",
    "* 1D Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyjup] *",
   "language": "python",
   "name": "conda-env-pyjup-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
